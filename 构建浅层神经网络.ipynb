{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预处理数据\n",
    "#oTensor()起到的作用是把PIL.Image或者numpy.narray数据类型转变为torch.FloatTensor类型，shape是C*H*W，数值范围缩小为[0.0, 1.0]。\n",
    "#0.5和0.5代表均值和方差，均一化；三通道里边3个数\n",
    "transform = tv.transforms.Compose([tv.transforms.ToTensor(),\n",
    "                                  tv.transforms.Normalize((0.5,), (0.5,)),\n",
    "                             ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Using downloaded and verified file: ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Using downloaded and verified file: ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Using downloaded and verified file: ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#ataLoader是PyTorch中数据读取重要接口，用PyTorch来训练模型基本都会用到该接口，接口将自定义的Dataset根据batch size大小、是否shuffle等封装成一个Batch Size大小的Tensor，用于后面的训练。\n",
    "train_ts = tv.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_ts = tv.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_dl = DataLoader(train_ts, batch_size=32, shuffle=True, drop_last=False)\n",
    "test_dl = DataLoader(test_ts, batch_size=64, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入层：784个神经元\n",
    "#隐藏层：100个神经元\n",
    "#输出层：10个神经元\n",
    "\n",
    "model = t.nn.Sequential(\n",
    "   t.nn.Linear(784, 100),\n",
    "   t.nn.ReLU(),\n",
    "   t.nn.Linear(100, 10),\n",
    "   t.nn.LogSoftmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数--均方误差损失与优化函数\n",
    "loss_fn = t.nn.NLLLoss(reduction=\"mean\")\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run in step : 0\n",
      "100 0.4118703603744507\n",
      "200 0.5581432580947876\n",
      "300 0.24970321357250214\n",
      "400 0.17116037011146545\n",
      "500 0.2641041874885559\n",
      "600 0.38658925890922546\n",
      "700 0.12484250217676163\n",
      "800 0.4279106557369232\n",
      "900 0.1375202238559723\n",
      "1000 0.22412562370300293\n",
      "1100 0.3093990683555603\n",
      "1200 0.1526477038860321\n",
      "1300 0.2435932159423828\n",
      "1400 0.2934589684009552\n",
      "1500 0.564362645149231\n",
      "1600 0.15247757732868195\n",
      "1700 0.44141441583633423\n",
      "1800 0.08823318779468536\n",
      "run in step : 1\n",
      "100 0.22151604294776917\n",
      "200 0.2081320434808731\n",
      "300 0.18304476141929626\n",
      "400 0.13293762505054474\n",
      "500 0.24954016506671906\n",
      "600 0.23794038593769073\n",
      "700 0.16781719028949738\n",
      "800 0.12840025126934052\n",
      "900 0.0952371209859848\n",
      "1000 0.23072166740894318\n",
      "1100 0.46371299028396606\n",
      "1200 0.30126112699508667\n",
      "1300 0.381339967250824\n",
      "1400 0.09298519045114517\n",
      "1500 0.11991730332374573\n",
      "1600 0.4551672041416168\n",
      "1700 0.039841894060373306\n",
      "1800 0.16063179075717926\n",
      "run in step : 2\n",
      "100 0.3408887982368469\n",
      "200 0.296337366104126\n",
      "300 0.13817785680294037\n",
      "400 0.2089039534330368\n",
      "500 0.3756535053253174\n",
      "600 0.19511137902736664\n",
      "700 0.32605403661727905\n",
      "800 0.13949695229530334\n",
      "900 0.04040353000164032\n",
      "1000 0.22191676497459412\n",
      "1100 0.1660715937614441\n",
      "1200 0.12575361132621765\n",
      "1300 0.44074857234954834\n",
      "1400 0.313218355178833\n",
      "1500 0.12876248359680176\n",
      "1600 0.05499264597892761\n",
      "1700 0.15895430743694305\n",
      "1800 0.3273801803588867\n",
      "run in step : 3\n",
      "100 0.047387901693582535\n",
      "200 0.016860399395227432\n",
      "300 0.1250215321779251\n",
      "400 0.09407306462526321\n",
      "500 0.15650226175785065\n",
      "600 0.07395823299884796\n",
      "700 0.05275079607963562\n",
      "800 0.02516692504286766\n",
      "900 0.1336769163608551\n",
      "1000 0.028465159237384796\n",
      "1100 0.010947156697511673\n",
      "1200 0.12343276292085648\n",
      "1300 0.0653681755065918\n",
      "1400 0.1963515728712082\n",
      "1500 0.09957751631736755\n",
      "1600 0.14570221304893494\n",
      "1700 0.08866061270236969\n",
      "1800 0.11249265819787979\n",
      "run in step : 4\n",
      "100 0.059771403670310974\n",
      "200 0.02570432610809803\n",
      "300 0.01697426289319992\n",
      "400 0.2784670293331146\n",
      "500 0.019680863246321678\n",
      "600 0.0820019319653511\n",
      "700 0.024765798822045326\n",
      "800 0.008322327397763729\n",
      "900 0.1061263307929039\n",
      "1000 0.03757258132100105\n",
      "1100 0.08263655751943588\n",
      "1200 0.3148908019065857\n",
      "1300 0.08264398574829102\n",
      "1400 0.1904171109199524\n",
      "1500 0.030531365424394608\n",
      "1600 0.02105060964822769\n",
      "1700 0.015506751835346222\n",
      "1800 0.13278451561927795\n"
     ]
    }
   ],
   "source": [
    "#训练,view相当于reshape;\n",
    "for s in range(5):\n",
    "   print(\"run in step : %d\"%s)\n",
    "   for i, (x_train, y_train) in enumerate(train_dl):\n",
    "       x_train = x_train.view(x_train.shape[0], -1)\n",
    "       y_pred = model(x_train)\n",
    "       train_loss = loss_fn(y_pred, y_train)\n",
    "       if (i + 1) % 100 == 0:\n",
    "           print(i + 1, train_loss.item())\n",
    "       model.zero_grad()\n",
    "       train_loss.backward()\n",
    "       optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total acc : 0.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#预测\n",
    "total = 0;\n",
    "correct_count = 0\n",
    "for test_images, test_labels in test_dl:\n",
    "   for i in range(len(test_labels)):\n",
    "       image = test_images[i].view(1, 784)#reshape\n",
    "       with t.no_grad():#预测时不要计算梯度\n",
    "           pred_labels = model(image)\n",
    "       plabels = t.exp(pred_labels)#实现以e为底的指数\n",
    "       probs = list(plabels.numpy()[0])\n",
    "       pred_label = probs.index(max(probs))\n",
    "       true_label = test_labels.numpy()[i]\n",
    "       if pred_label == true_label:\n",
    "           correct_count += 1\n",
    "       total += 1\n",
    "print(\"total acc : %.2f\\n\"%(correct_count / total))\n",
    "t.save(model, './nn_mnist_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183, 7.3891, 2.7183])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.FloatTensor([1,2,1])\n",
    "x.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'pytorch'",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
